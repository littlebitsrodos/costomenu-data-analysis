name: Daily Crisp Data Sync

on:
  schedule:
    # Runs at 03:00 UTC every day
    - cron: '0 3 * * *'
  workflow_dispatch: # Allows you to click "Run Now" button manually

jobs:
  fetch-and-sync:
    runs-on: ubuntu-latest
    permissions:
      contents: write # REQUIRED: Allows the bot to push the new data back to the repo

    steps:
      - name: 1. Checkout Repository
        uses: actions/checkout@v3

      - name: 2. Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: 3. Install Dependencies
        run: |
          pip install crisp-api python-dotenv

      - name: 4. Run Fetch Script
        # We inject your secrets into the script environment
        env:
          CRISP_PLUGIN_IDENTIFIER: ${{ secrets.CRISP_PLUGIN_IDENTIFIER }}
          CRISP_PLUGIN_KEY: ${{ secrets.CRISP_PLUGIN_KEY }}
          CRISP_WEBSITE_ID: ${{ secrets.CRISP_WEBSITE_ID }}
        run: |
          # Runs the script. The script should be updated to handle "incremental" updates or just overwrite.
          # For now, it runs as is.
          python fetch_crisp_tickets.py

      - name: 5. Commit and Push Changes
        run: |
          # Identify as the "GitHub Actions Bot"
          git config --global user.name 'GitHub Actions Bot'
          git config --global user.email 'actions@github.com'
          
          # Stage the JSON file (update this filename if it changes daily)
          # Note: The current script produces 'crisp_tickets_export_YYYYMMDD.json'. 
          # You might want to rename it to a static 'crisp_data.json' in the script 
          # so the dashboard always finds it.
          git add crisp_full_backup.json || true
          git add crisp_tickets_export_*.json || true
          
          # Only commit if there is new data
          git diff --quiet && git diff --staged --quiet || (git commit -m "data: daily crisp sync" && git push)
